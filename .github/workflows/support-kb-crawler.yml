name: Support KB Weekly Crawler

on:
  schedule:
    # Run every Monday at 2 AM UTC
    - cron: '0 2 * * 1'
  workflow_dispatch: # Allow manual trigger

env:
  NODE_VERSION: 20

jobs:
  crawl-kb:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}

      - name: Setup pnpm
        uses: pnpm/action-setup@v3
        with:
          version: 9

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Run KB Crawler
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_SERVICE_ROLE_KEY: ${{ secrets.SUPABASE_SERVICE_ROLE_KEY }}
          # Embeddings: OpenAI or Gemini (crawler uses embeddings)
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          GEMINI_API_KEY: ${{ secrets.GEMINI_API_KEY }}
          SUPPORT_EMBEDDING_PROVIDER: ${{ secrets.SUPPORT_EMBEDDING_PROVIDER || 'openai' }}
          NEXT_PUBLIC_APP_URL: ${{ secrets.NEXT_PUBLIC_APP_URL || 'https://bookiji.com' }}
        run: pnpm tsx scripts/crawl-kb.ts

      - name: Upload crawl logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: crawl-logs-${{ github.run_id }}
          path: |
            crawl-*.log
          retention-days: 7
          if-no-files-found: ignore

      - name: Notify on failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            console.log('⚠️ KB Crawler failed. Check logs in artifacts.');
